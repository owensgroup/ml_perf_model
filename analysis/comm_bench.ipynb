{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "num_gpus = 4\n",
    "epsilon = 4e-4\n",
    "saturation_th = 0.05\n",
    "superscript = str.maketrans(\"0123456789\", \"⁰¹²³⁴⁵⁶⁷⁸⁹\")\n",
    "collectives = ['all_to_all', 'all_to_allv', 'all_reduce', 'all_gather', 'all_gather_base', 'reduce', 'reduce_scatter']\n",
    "mul_factor_funcs = {\n",
    "    'all_to_all': lambda n: (n-1) / n,\n",
    "    'all_to_allv': lambda n: (n-1) / n,\n",
    "    'all_reduce': lambda n: 2 * (n-1) / n,\n",
    "    'all_gather': lambda n: (n-1) / n,\n",
    "    'all_gather_base': lambda n: (n-1) / n,\n",
    "    'reduce': lambda n: 1,\n",
    "    'reduce_scatter': lambda n: (n-1) / n\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce05fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_collectives = len(collectives)\n",
    "data = {}\n",
    "for idx, collective in enumerate(collectives):\n",
    "    data[collective] = {\n",
    "        'size': [],\n",
    "        'latency': [],\n",
    "        'alg_bw': [],\n",
    "        'bus_bw': []\n",
    "    }\n",
    "    filename = '../3rdparty/param/train/comms/pt/bench_results/{}_{}.txt'.format(collective, num_gpus)\n",
    "    header_found = False\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if re.search('COMMS-RES', line):\n",
    "                if not header_found:\n",
    "                    header_found = True\n",
    "                    continue\n",
    "                data[collective]['size'].append(int(line.split('\\t')[2].lstrip('\\t')))\n",
    "                data[collective]['latency'].append(float(line.split('\\t')[4].lstrip('\\t')))\n",
    "                data[collective]['alg_bw'].append(float(line.split('\\t')[-2].rstrip('\\n')) + epsilon)\n",
    "                data[collective]['bus_bw'].append(float(line.split('\\t')[-1].rstrip('\\n')) + epsilon)\n",
    "        data[collective]['size'] = np.array(data[collective]['size'])\n",
    "        data[collective]['latency'] = np.array(data[collective]['latency'])\n",
    "        data[collective]['alg_bw'] = np.array(data[collective]['alg_bw'])\n",
    "        data[collective]['bus_bw'] = np.array(data[collective]['bus_bw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada41dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get turning points of the bus BW curve for a collective\n",
    "def get_turning_points(collective_data, ratio_th=0.05):\n",
    "    num_samples = len(collective_data['bus_bw'])\n",
    "    ratios = []\n",
    "    for idx in range(num_samples):\n",
    "        if idx == 0 or idx == num_samples - 1:\n",
    "            ratios.append(-1)\n",
    "            continue\n",
    "        bw = collective_data['bus_bw'][idx]\n",
    "        prev_bw = collective_data['bus_bw'][idx-1]\n",
    "        next_bw = collective_data['bus_bw'][idx+1]\n",
    "        ratios.append(next_bw * prev_bw / bw / bw)\n",
    "\n",
    "    sats = []\n",
    "    incr = []\n",
    "    for idx in reversed(range(num_samples)):\n",
    "        if idx == 0 or idx == num_samples - 1:\n",
    "            continue\n",
    "        if abs(ratios[idx] - 1) > ratio_th:\n",
    "            if not sats or sats[-1] == idx+1:\n",
    "                sats.append(idx)\n",
    "            elif not incr or incr[-1] == idx+1:\n",
    "                incr.append(idx)\n",
    "\n",
    "    increment_idx = int(np.mean(incr))\n",
    "    saturation_idx = int(np.mean(sats))\n",
    "\n",
    "    return increment_idx, saturation_idx\n",
    "\n",
    "def get_feature(collective_data):\n",
    "    max_bus_bw = collective_data['bus_bw'].max() # Pick the bw for the 3rd section of the curves\n",
    "    incr_idx, sats_idx = get_turning_points(collective_data)\n",
    "    incr_p, sats_p = int(np.log2(collective_data['size'][incr_idx])), int(np.log2(collective_data['size'][sats_idx])) # log sizes of both incr point and sats point\n",
    "    min_bus_bw = collective_data['bus_bw'][incr_idx] # Adaptively pick the bw for the 1st section of the curves\n",
    "    slope = (np.log10(max_bus_bw / min_bus_bw)) / (sats_p - incr_p)\n",
    "    overhead = collective_data['latency'][0]\n",
    "    return (incr_p, sats_p, slope, min_bus_bw, max_bus_bw, overhead)\n",
    "\n",
    "def sigmoid(x, L ,x0, k, b):\n",
    "    y = L / (1 + np.exp(-k*(x-x0)))+b\n",
    "    return (y)\n",
    "\n",
    "def fit_sigmoid_bw_predictor(collective_data):\n",
    "    xdata = np.log2(collective_data['size'])\n",
    "    ydata = np.log10(collective_data['bus_bw'])\n",
    "    p0 = [ydata.max(), \n",
    "            np.median(xdata),\n",
    "            1,\n",
    "            ydata.min()] # this is an mandatory initial guess\n",
    "    popt, _ = curve_fit(sigmoid, xdata, ydata, p0, method='dogbox')\n",
    "    return popt\n",
    "\n",
    "def get_linear_bw(s, s0, k, b):\n",
    "    return 10 ** ((s - s0) * k) * b\n",
    "\n",
    "def get_sigmoid_bw(s, f_sigmoid):\n",
    "    return 10 ** f_sigmoid(s)\n",
    "\n",
    "def predict_linear(size, f, incr_p, sats_p, slope, min_bw, max_bw, overhead):\n",
    "    log_size = np.log2(size)\n",
    "    if log_size <= incr_p:\n",
    "        return overhead\n",
    "    elif log_size >= sats_p:\n",
    "        return size / max_bw * f(num_gpus) / 1e3 + overhead\n",
    "    else:\n",
    "        bw = get_linear_bw(log_size, incr_p, slope, min_bw)\n",
    "        return size / bw * f(num_gpus) / 1e3 + overhead\n",
    "\n",
    "def predict_sigmoid(size, f_sigmoid, f, incr_p, sats_p, slope, min_bw, max_bw, overhead):\n",
    "    log_size = np.log2(size)\n",
    "    if log_size <= incr_p:\n",
    "        return overhead\n",
    "    elif log_size >= sats_p:\n",
    "        return size / max_bw * f(num_gpus) / 1e3 + overhead\n",
    "    else:\n",
    "        bw = get_sigmoid_bw(log_size, f_sigmoid)\n",
    "        return size / bw * f(num_gpus) / 1e3\n",
    "\n",
    "# Get slopes of for the 2nd section of the curves\n",
    "stats = {}\n",
    "sigmoid_fs = {}\n",
    "for idx, collective in enumerate(collectives):\n",
    "    stats[collective] = get_feature(data[collective])\n",
    "    popt = fit_sigmoid_bw_predictor(data[collective])\n",
    "    sigmoid_fs[collective] = lambda x: sigmoid(x, *popt)\n",
    "    # plt.plot(np.log2(data[collective]['size']), np.log10(data[collective]['bus_bw']))\n",
    "    # plt.plot(np.log2(data[collective]['size']), sigmoid(np.log2(data[collective]['size']), *sigmoid_popt[collective]))\n",
    "\n",
    "    # Prediction\n",
    "    print(\"----- {} -----\".format(collective))\n",
    "    for idx, size in enumerate(data[collective]['size']):\n",
    "        f_mul_factor = mul_factor_funcs[collective]\n",
    "        f_sigmoid_bw = sigmoid_fs[collective]\n",
    "        print(\"{:.2f}, {:.2f}, {:.2f}\".format(\n",
    "            data[collective]['latency'][idx], \n",
    "            predict_linear(size, f_mul_factor, *stats[collective]),\n",
    "            predict_sigmoid(size, f_sigmoid_bw, f_mul_factor, *stats[collective])\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ff6f3",
   "metadata": {},
   "source": [
    "Current limitations:\n",
    "- Prediction error is high near the two turning points. Probably need another way to fit the curve. Updates: sigmoid can fit the corners well.\n",
    "- Is there a way to directly get the min/max BW from device connection configuration w/o benchmarking? Can the bus BW be derived from the algo BW which seems to follow a pattern (50, 75, 87.5 GB/s)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289a00c",
   "metadata": {},
   "source": [
    "e.g. 4 GPUs, all_to_all, each GPU sends 1/4 elements to each of the other GPUs\n",
    "- --b/--e (in bytes per rank): 16, 32, 64...\n",
    "- allSizes (in bytes per rank): 16, 32, 64...\n",
    "- memSize / size (B) in printed results (in bytes per rank): 16, 32, 64...\n",
    "- num-elements in printed results (in elements COMMUNICATED per rank-pair): 1, 2, 4...\n",
    "\n",
    "commsParams.element_size: 4 (float)\n",
    "comm_fn: backendFuncs.collectiveFunc[commsParams.collective]\n",
    "comms.py comm op line 1202 calls runColl line 258\n",
    "--z/commsParamsHolderBase's blockingFlag/~asyncOp 1: non-blocking, 0: blocking\n",
    "gatherBenchTime line 767: gather bench time stored in tensors on each device to a list of tensors on rank 0.\n",
    "\n",
    "param pytorch_dist_backend: all_to_all line 163 calls dist.all_to_all_single line 170, wait function called at line 389\n",
    "dlrm extend_distributed: alltoall line 597 calls All2All_Req line 404 calls dist.all_to_all_single line 429 (list of local tensors concatenated and flatten to 1D)\n",
    "\n",
    "e.g. batched_emb\n",
    "dist.all_to_all_single: input_split_sizes (how tables are distributed to devices, e.g. 13 tables and [2,3,3,5] on 4 GPUs), output_split_sizes (how batches are distributed to devices; set to None for equal distribution, e.g. batch size 2048 -> 512 per GPU)\n",
    "common case: input_split_sizes not None, output_split_sizes None\n",
    "\n",
    "- reduce scatter: memSize measures the INPUT size in bytes per rank (equal to total OUTPUT size on all devices)\n",
    "- all gather: memSize measures the OUTPUT size in bytes per rank (equal to total INPUT size on all devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 18))\n",
    "for idx, collective in enumerate(collectives):\n",
    "\n",
    "    ax = fig.add_subplot(num_of_collectives, 2, idx * 2 + 1)\n",
    "    ax.set_title('{} latency'.format(collective))\n",
    "    ax.plot(data[collective]['size'], data[collective]['latency'], marker='o')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim([1e1, 1e6])\n",
    "    ax.set_xticks([2**i for i in range(2, 33)])\n",
    "    ax.set_xticklabels([\"2{}\".format(str(j).translate(superscript)) for j in range(2, 33)])\n",
    "    \n",
    "    ax = fig.add_subplot(num_of_collectives, 2, idx * 2 + 2)\n",
    "    ax.set_title('{} BW'.format(collective))\n",
    "    ax.plot(data[collective]['size'], data[collective]['alg_bw'], marker='o')\n",
    "    ax.plot(data[collective]['size'], data[collective]['bus_bw'], marker='o')\n",
    "    ax.legend(['alg_bw', 'bus_bw'])\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim([1e-3, 1e2])\n",
    "    ax.set_xticks([2**i for i in range(2, 33)])\n",
    "    ax.set_xticklabels([\"2{}\".format(str(j).translate(superscript)) for j in range(2, 33)])\n",
    "\n",
    "fig.tight_layout(pad=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c760c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax1 = fig.add_subplot(3, 1, 1)\n",
    "ax2 = fig.add_subplot(3, 1, 2)\n",
    "ax3 = fig.add_subplot(3, 1, 3)\n",
    "for idx, collective in enumerate(collectives):\n",
    "    \n",
    "    ax1.plot(data[collective]['size'], data[collective]['latency'], marker='o')\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_ylim([1e1, 1e6])\n",
    "    ax1.set_xticks([2**i for i in range(2, 33)])\n",
    "    ax1.set_xticklabels([\"2{}\".format(str(j).translate(superscript)) for j in range(2, 33)])\n",
    "    ax1.set_xlabel(\"Message size (bytes)\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Latency (us)\", fontsize=12)\n",
    "\n",
    "    ax2.plot(data[collective]['size'], data[collective]['bus_bw'], marker='o')\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_ylim([1e-3, 1e2])\n",
    "    ax2.set_xticks([2**i for i in range(2, 33)])\n",
    "    ax2.set_xticklabels([\"2{}\".format(str(j).translate(superscript)) for j in range(2, 33)])\n",
    "    ax2.set_xlabel(\"Message size (bytes)\", fontsize=12)\n",
    "    ax2.set_ylabel(\"Bus BW (GB/s)\", fontsize=12)\n",
    "\n",
    "    ax3.plot(data[collective]['size'], data[collective]['alg_bw'], marker='o')\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.set_ylim([1e-3, 1e2])\n",
    "    ax3.set_xticks([2**i for i in range(2, 33)])\n",
    "    ax3.set_xticklabels([\"2{}\".format(str(j).translate(superscript)) for j in range(2, 33)])\n",
    "    ax3.set_xlabel(\"Message size (bytes)\", fontsize=12)\n",
    "    ax3.set_ylabel(\"Alg BW (GB/s)\", fontsize=12)\n",
    "\n",
    "ax1.legend(collectives)\n",
    "ax2.legend(collectives)\n",
    "ax3.legend(collectives)\n",
    "fig.suptitle(\"Communication collectives microbenchmark on a quad-V100 DGX-1\", fontsize=14)\n",
    "fig.tight_layout(pad=0.5)\n",
    "plt.savefig('../3rdparty/param/train/comms/pt/latency_bw.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73883e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collective = \"all_to_all\"\n",
    "for idx, size in enumerate(data[collective]['size']):\n",
    "    bus_bw = data[collective]['bus_bw'][idx]\n",
    "    f = mul_factor_funcs[collective]\n",
    "    pred_t = size / bus_bw * f(num_gpus) / 1e3\n",
    "    print(pred_t, data[collective]['latency'][idx])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc5ba239c788f0d7fda465cb2deafb66b051c8a8c0c0b2e8ed6bd70169f4519c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
