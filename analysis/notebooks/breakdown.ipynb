{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "import json, sys, re, os\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.rcParams['figure.max_open_warning'] = 50\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "sys.path.insert(0, os.getcwd() + \"/../../\")\n",
    "from analysis.utils import PM_HOME, GPU_NAME\n",
    "from analysis.trace_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "num_gpus = 1\n",
    "batch_size = 2048\n",
    "iters = 10\n",
    "\n",
    "flattens = []\n",
    "for model_name in ['DLRM_default', 'DLRM_MLPerf', 'DLRM_DDP']:\n",
    "    module_marker = \"DLRM \" if \"DLRM\" in model_name else \"## Forward ##\"\n",
    "    trace_file = '{}/data/{}/e2e/{}/{}_{}.json'.format(PM_HOME, GPU_NAME, model_name, num_gpus, batch_size)\n",
    "\n",
    "    runtime_no_pf = -1\n",
    "    log_file = \"{}/data/{}/e2e/{}/{}_{}.log\".format(PM_HOME, GPU_NAME, model_name, num_gpus, batch_size)\n",
    "    if os.path.exists(log_file):\n",
    "        for line in open(log_file, 'r'):\n",
    "            if re.search(\"Overall per-batch\", line):\n",
    "                runtime_no_pf = float(line.split(' ')[4]) * 1000 * iters # us\n",
    "\n",
    "    trimmed_trace_file = trim_trace_by_num_iter(trace_file, iters=iters, trimmed_file='/tmp/{}_{}_{}'.format(model_name, num_gpus, batch_size))\n",
    "    with open(trimmed_trace_file) as f:\n",
    "        trace = json.load(f)\n",
    "\n",
    "    roots, cc, corrected_start_time, corrected_end_time, sum_skipped_intervals = process_event_hierarchy(trace['traceEvents'], skip_module=False, module_marker=module_marker)\n",
    "    host_runtime = corrected_end_time - corrected_start_time - sum_skipped_intervals\n",
    "    device_runtime = host_runtime\n",
    "    ops = []\n",
    "    get_operators(roots, ops)\n",
    "    op_device_runtime = get_device_runtime(ops, cc) # dict: op ex_id -> all its device calls and stats\n",
    "    dt_breakdown = device_runtime_breakdown(roots, op_device_runtime, depth=0)\n",
    "    flatten = {}\n",
    "    for stream, v in dt_breakdown.items():\n",
    "        flatten[stream] = {}\n",
    "        get_major_device_results(device_runtime, dt_breakdown[stream], flatten[stream])\n",
    "    flattens.append((model_name, flatten, runtime_no_pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(flattens, truncate=20):\n",
    "    fig, axes = plt.subplots(nrows=len(flattens), ncols=1, figsize=(12, 5))\n",
    "\n",
    "    cmap = plt.get_cmap('tab20b', truncate+1)\n",
    "    gray = np.array([0.5, 0.5, 0.5, 1])\n",
    "    colors = cmap(np.linspace(0, 1, truncate+1))\n",
    "    colors[-1, :] = gray\n",
    "    legend_dict = None\n",
    "\n",
    "    for idx, tuple in enumerate(flattens):\n",
    "        model_name, flatten, runtime_no_pf = tuple\n",
    "        flatten = flatten[7]\n",
    "        per_op = {}\n",
    "        total = 0.0\n",
    "        for k, v in flatten.items():\n",
    "            if k == 'total' or 'DLRM ' in k[0] or 'module' in k[0]: # Skip all labels\n",
    "                continue\n",
    "            k0 = k[0] if '#' not in k[0] else k[0].split('#')[0]\n",
    "            if k0 not in per_op.keys():\n",
    "                per_op[k0] = 0.0\n",
    "            per_op[k0] += v['runtime']\n",
    "            total += v['runtime']\n",
    "            \n",
    "        tmp = sorted(per_op.items(), key=lambda x: x[1], reverse=True)\n",
    "        op = [x[0] for x in tmp]\n",
    "        p = [x[1] / total for x in tmp]\n",
    "        df0 = pd.DataFrame({\n",
    "            'Active time': [flatten['total']['runtime'] / runtime_no_pf],\n",
    "            'Idle time': [1 - flatten['total']['runtime'] / runtime_no_pf]\n",
    "        })\n",
    "        if len(p) > truncate:\n",
    "            p[truncate-1] = sum(p[(truncate-1):])\n",
    "            p = p[:truncate]\n",
    "            op[truncate-1] = \"others\"\n",
    "            op = op[:truncate]\n",
    "        df = pd.DataFrame([p], columns=op)\n",
    "        active_time = df0['Active time'].item()\n",
    "        idle_time = df0['Idle time'].item()\n",
    "        df = df * active_time\n",
    "        df['Idle'] = idle_time\n",
    "        \n",
    "        if idx == 0:\n",
    "            new_colors = colors\n",
    "            legend_dict = {k: v for k, v in zip(df.columns.values.tolist(), colors)}\n",
    "        else:\n",
    "            assert legend_dict is not None\n",
    "            columns = df.columns.values.tolist()\n",
    "            new_colors = [legend_dict[c] if c in legend_dict.keys() else plt.get_cmap('tab20b')(truncate + idx) for c in columns]\n",
    "\n",
    "        new_cmp = ListedColormap(new_colors)\n",
    "        df.plot(stacked=True, legend=False, kind='barh', width=0.05, cmap=new_cmp, ax=axes[idx])\n",
    "        vals = axes[idx].get_xticks()\n",
    "        axes[idx].set_xticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "        axes[idx].set_xlim((0.0, 1.0))\n",
    "        axes[idx].set_yticks([])\n",
    "        axes[idx].set_yticklabels([])\n",
    "        axes[idx].set_ylim((-0.03, 0.03))\n",
    "        axes[idx].set_title(model_name, fontsize=14)\n",
    "\n",
    "        ax2 = axes[idx].twiny()\n",
    "        ax2.set_xticks([x * active_time for x in np.arange(0, 1.2, 0.2)])\n",
    "        ax2.set_xbound(axes[idx].get_xbound())\n",
    "        ax2.set_xticklabels(['{:,.0%}'.format(x) for x in np.arange(0, 1.2, 0.2)])\n",
    "\n",
    "    handels, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handels, labels, loc=\"lower center\", ncol=5, bbox_to_anchor=(0.5, -0.3), frameon=False, fontsize=10.5)\n",
    "    plt.tight_layout()\n",
    "    plt.rcParams['figure.figsize'] = [12, 5]\n",
    "    plt.savefig('{}/data/{}/e2e/active_time_breakdown.pdf'.format(PM_HOME, GPU_NAME, model_name), bbox_inches='tight')\n",
    "    plt.savefig('{}/data/{}/e2e/active_time_breakdown.png'.format(PM_HOME, GPU_NAME, model_name), bbox_inches='tight')\n",
    "\n",
    "plot_bar_chart(flattens)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02372877dc9d511b3b18d0e90d7fc10386e618ab92d8e9830d393832c733bc2e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('zhongyi': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
