{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b28a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from IPython.core.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, re\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.rcParams['figure.max_open_warning'] = 50\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "sys.path.insert(0, os.getcwd() + \"/../../\")\n",
    "from analysis.utils import PM_HOME, GPU_NAME\n",
    "from analysis.trace_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65133481",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 10\n",
    "model_names = ['DLRM_default', 'DLRM_MLPerf', 'DLRM_DDP', 'resnet50', 'inception_v3', 'Transformer']\n",
    "batch_0_sizes = [512, 512, 512, 16, 16, 64]\n",
    "num_batch_sizes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac77822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while num_batch_sizes > 0:\n",
    "#     for idx, model_name in enumerate(model_names):\n",
    "#         print(model_name)\n",
    "#         module_marker = \"DLRM \" if \"DLRM\" in model_name else \"## Forward ##\"\n",
    "#         trace_file = '{}/data/{}/e2e/{}/1_{}.json'.format(\n",
    "#             PM_HOME, \n",
    "#             GPU_NAME, \n",
    "#             model_name, \n",
    "#             2 ** (4 - num_batch_sizes) * batch_0_sizes[idx]\n",
    "#         )\n",
    "\n",
    "#         trimmed_trace_file = trim_trace_by_num_iter(trace_file, iters=iters)\n",
    "#         with open(trimmed_trace_file) as f:\n",
    "#             trace = json.load(f)\n",
    "            \n",
    "#         roots, cc, corrected_start_time, corrected_end_time, sum_skipped_intervals = \\\n",
    "#             process_event_hierarchy(trace['traceEvents'], skip_module=False, module_marker=module_marker)\n",
    "#         host_runtime = corrected_end_time - corrected_start_time - sum_skipped_intervals\n",
    "#         device_runtime = host_runtime\n",
    "#         ops = []\n",
    "#         get_operators(roots, ops)\n",
    "\n",
    "#         op_device_runtime = get_device_runtime(ops, cc) # dict: op ex_id -> all its device calls and stats\n",
    "#         dt_breakdown = device_runtime_breakdown(roots, op_device_runtime, depth=0)\n",
    "#         truncate_count = 10\n",
    "#         flatten = {}\n",
    "#         for stream, v in dt_breakdown.items():\n",
    "#             flatten[stream] = {}\n",
    "#             get_major_device_results(device_runtime, dt_breakdown[stream], flatten[stream])\n",
    "        \n",
    "#         for stream, v in flatten.items():\n",
    "#             runtime_no_pf = -1\n",
    "#             log_file = \"{}/data/{}/e2e/{}/1_{}.log\".format(PM_HOME, GPU_NAME, model_name, batch_0_sizes[idx] * 4)\n",
    "#             if os.path.exists(log_file):\n",
    "#                 for line in open(log_file, 'r'):\n",
    "#                     if re.search(\"Overall per-batch\", line):\n",
    "#                         runtime_no_pf = float(line.split(' ')[4]) * 1000 * iters # us\n",
    "\n",
    "#             per_op = {}\n",
    "#             total = 0.0\n",
    "#             for k, vv in v.items():\n",
    "#                 if k == 'total' or 'DLRM ' in k[0] or 'module' in k[0]: # Skip all labels\n",
    "#                     continue\n",
    "#                 k0 = k[0] if '#' not in k[0] else k[0].split('#')[0]\n",
    "#                 if k0 not in per_op.keys():\n",
    "#                     per_op[k0] = 0.0\n",
    "#                 per_op[k0] += vv['runtime']\n",
    "#                 total += vv['runtime']\n",
    "\n",
    "#             tmp = sorted(per_op.items(), key=lambda x: x[1], reverse=True)\n",
    "#             op = [x[0] for x in tmp]\n",
    "#             p = [x[1] / total for x in tmp]\n",
    "#             df0 = pd.DataFrame({\n",
    "#                 'Active time': [v['total']['runtime'] / runtime_no_pf],\n",
    "#                 'Idle time': [1 - v['total']['runtime'] / runtime_no_pf]\n",
    "#             })\n",
    "#             print(df0)\n",
    "#     num_batch_sizes -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ecf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "UTILS = [\n",
    "    [0.5383, 0.7027, 0.8234, 0.9107],\n",
    "    [0.5388, 0.6577, 0.7997, 0.9073],\n",
    "    [0.3326, 0.4272, 0.6063, 0.7457],\n",
    "    [0.8129, 0.9572, 0.9839, 0.9889],\n",
    "    [0.6753, 0.8500, 0.9723, 0.9829],\n",
    "    [0.8630, 0.9345, 0.9514, 0.9651]\n",
    "]\n",
    "\n",
    "dfs = {}\n",
    "for idx, model in enumerate(model_names):\n",
    "    gpu_util = UTILS[idx]\n",
    "    dfs[model] = pd.DataFrame([\n",
    "        [gpu_util[i], 1 - gpu_util[i]] for i in range(0, num_batch_sizes)\n",
    "    ], columns=['active', 'idle'], index=[batch_0_sizes[idx] * (2**i) for i in range(0, num_batch_sizes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0633745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 10\n",
    "idx = 0\n",
    "bar_width = 8\n",
    "bar_gap = 3\n",
    "model_gap = 60\n",
    "xticks = []\n",
    "xticklabels = []\n",
    "yticks = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "yticklabels = [\"{:.0f}%\".format(x*100) for x in yticks]\n",
    "for model_name, df in dfs.items():\n",
    "    plt.grid(axis='y')\n",
    "    labels = [model_gap * (idx+1) + (bar_width + bar_gap) * i - (bar_width + bar_gap) * (num_batch_sizes - 1) / 2 for i in range(0, 4)]\n",
    "    plt.bar(labels, df['active'], bar_width, color=[plt.get_cmap(\"Set2\")(idx)] * num_batch_sizes)\n",
    "    plt.bar(labels, df['idle'], bar_width, bottom=df['active'], color=['gray'] * num_batch_sizes)\n",
    "    # for i, x in enumerate(labels):\n",
    "    #     plt.text(x, df['active'].values[i]-0.04, \"{:.2f}%\".format(df['active'].values[i]*100), horizontalalignment='center', verticalalignment='center', size=fontsize)\n",
    "    plt.text(model_gap * (idx+1), 1.08, model_name, horizontalalignment='center', verticalalignment='center', size=fontsize*2)\n",
    "    xticks.extend(labels)\n",
    "    xticklabels.extend([batch_0_sizes[idx] * (2**i) for i in range(num_batch_sizes)])\n",
    "    idx += 1\n",
    "plt.xticks(xticks, labels=xticklabels, fontsize=fontsize*1.5)\n",
    "plt.yticks(yticks, labels=yticklabels, fontsize=fontsize*1.5)\n",
    "plt.xlabel(\"Batch Size\", fontsize=fontsize*2)\n",
    "plt.ylabel(\"Percentage\", fontsize=fontsize*2)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y')\n",
    "plt.rcParams['figure.figsize'] = [20, 8]\n",
    "plt.savefig('{}/data/{}/e2e/active_idle_split.pdf'.format(PM_HOME, GPU_NAME), bbox_inches='tight')\n",
    "plt.savefig('{}/data/{}/e2e/active_idle_split.png'.format(PM_HOME, GPU_NAME), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
