{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from pprint import pprint\n",
    "from IPython.core.display import display, HTML\n",
    "from scipy.stats.mstats import gmean \n",
    "import argparse, logging, tempfile, json, sys, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "plt.rcParams['figure.max_open_warning'] = 100\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from trace_utils import *\n",
    "from exec_graph_utils import *\n",
    "from ml_predictors.mlp import get_pretrained_net, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def abs_err(pred, real):\n",
    "    return abs((pred - real) / real)\n",
    "\n",
    "def err(pred, real):\n",
    "    return (pred - real) / real\n",
    "\n",
    "def gmae(x):\n",
    "    return np.exp(np.log(abs(x)).mean())\n",
    "\n",
    "def histogram(df, perc=True, bins=[0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.8, 1.0, 1.5, 2.0, 3.0, 4.0]):\n",
    "    count = len(df)\n",
    "    ret = {}\n",
    "    for idx, b in enumerate(bins):\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        ret[(bins[idx-1], bins[idx])] = 0\n",
    "    for x in df:\n",
    "        for idx, b in enumerate(bins):\n",
    "            if idx == 0:\n",
    "                continue\n",
    "            if x >= bins[idx-1] and x < bins[idx]:\n",
    "                ret[(bins[idx-1], bins[idx])] += 1\n",
    "                break\n",
    "    for b, c in sorted(ret.items(), key=lambda x: x[0]):\n",
    "        if perc:\n",
    "            print(\"{:.0f}% - {:.0f}%: {:.2f}%\".format(b[0] * 100, b[1] * 100, c / count * 100))\n",
    "        else:\n",
    "            print(\"{:.2f} - {:.2f}: {:.2f}%\".format(b[0], b[1], c / count * 100))\n",
    "    return ret\n",
    "\n",
    "def strip_unit(x):\n",
    "    for col in ['dram_read_throughput', 'dram_write_throughput', 'gld_requested_throughput', 'gld_throughput',\\\n",
    "               'gst_requested_throughput', 'gst_throughput', 'l2_read_throughput', 'l2_write_throughput', \\\n",
    "                'shared_load_throughput', 'shared_store_throughput']:\n",
    "        if col in x.keys():\n",
    "            if x[col].endswith('GB/s'):\n",
    "                x[col] = float(x[col].rstrip('GB/s'))\n",
    "            elif x[col].endswith('MB/s'):\n",
    "                x[col] = float(x[col].rstrip('MB/s')) / 1e3\n",
    "            elif x[col].endswith('B/s'):\n",
    "                x[col] = float(x[col].rstrip('B/s')) / 1e9\n",
    "            else:\n",
    "                raise Exception(\"Unrecognizable unit!\")\n",
    "    return x\n",
    "    \n",
    "def p2f(x):\n",
    "    for col in ['flop_dp_efficiency', 'flop_sp_efficiency', 'gld_efficiency', 'gst_efficiency', \\\n",
    "                'shared_efficiency', 'sm_efficiency', 'warp_execution_efficiency']:\n",
    "        if col in x.keys():\n",
    "            x[col] = float(str(x[col]).rstrip('%')) / 100.0\n",
    "    return x\n",
    "\n",
    "def strip_parenthesis(x):\n",
    "    for col in ['dram_utilization', 'l2_utilization', 'tex_utilization']:\n",
    "        if col in x.keys():\n",
    "            x[col] = x[col].strip('(').strip(')')\n",
    "    return x\n",
    "\n",
    "def process_smem(x):\n",
    "    # To bytes\n",
    "    if 'smem' in x.keys():\n",
    "        if x['smem'].endswith('MB'):\n",
    "            x['smem'] = int(float(x['smem'].rstrip('MB')) * 1024 * 1024)\n",
    "        elif x['smem'].endswith('KB'):\n",
    "            x['smem'] = int(float(x['smem'].rstrip('KB')) * 1024)\n",
    "        elif x['smem'].endswith('B'):\n",
    "            x['smem'] = int(x['smem'].rstrip('B'))\n",
    "        else:\n",
    "            raise Exception(\"Unrecognizable unit!\")\n",
    "    return x\n",
    "        \n",
    "def preprocessing(df):\n",
    "    df = df.apply(func=p2f, axis=1)\n",
    "    df = df.apply(func=strip_unit, axis=1)\n",
    "    df = df.apply(func=strip_parenthesis, axis=1)\n",
    "    df = df.apply(func=process_smem, axis=1)\n",
    "    df = df[(df['kernel_name'] != 'gemv2T_kernel') & (df['kernel_name'] != 'splitKreduce_kernel')]\n",
    "    return df\n",
    "\n",
    "def div_round_up(x, y):\n",
    "    return int((x + y - 1) / y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"MLPerf_1\"\n",
    "model_name = \"DLRM_default_1\"\n",
    "exec_graph_file = \"../data/{}_graph.json\".format(model_name)\n",
    "with open(exec_graph_file) as f:\n",
    "    graph = ExecutionGraph(json.load(f))\n",
    "overheads_file = \"./overheads_{}.json\".format(model_name)\n",
    "with open(overheads_file) as f:\n",
    "    overheads = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OP STATS ###\n",
      "op: AddmmBackward\n",
      "  count: 6\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: BmmBackward0\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: CatBackward\n",
      "  count: 2\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: IndexBackward\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: LookupFunction\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: LookupFunctionBackward\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: MseLossBackward\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: Optimizer.step#SGD.step\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: Optimizer.zero_grad#SGD.zero_grad\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: ReluBackward0\n",
      "  count: 5\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: SigmoidBackward\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: SliceBackward\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: TBackward\n",
      "  count: 6\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: TransposeBackward0\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: ViewBackward\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: []\n",
      "op: aten::add\n",
      "  count: 2\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 64], 'type': 'tensor'}, {'dtype': 'float', 'shape': [2048, 64], 'type': 'tensor'}, {'type': 'int', 'value': 1}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 9, 64], 'type': 'tensor'}, {'dtype': 'float', 'shape': [2048, 9, 64], 'type': 'tensor'}, {'type': 'int', 'value': 1}]\n",
      "op: aten::bmm\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 9, 64], 'type': 'tensor'}, {'dtype': 'float', 'shape': [2048, 64, 9], 'type': 'tensor'}]\n",
      "op: aten::broadcast_tensors\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: [{'size': 2, 'type': 'genericlist', 'value': [{'dtype': 'float', 'shape': [2048, 1], 'type': 'tensor'}, {'dtype': 'float', 'shape': [2048, 1], 'type': 'tensor'}]}]\n",
      "op: aten::cat\n",
      "  count: 2\n",
      "  unique inputs:\n",
      "  input: [{'size': 2, 'type': 'genericlist', 'value': [{'dtype': 'float', 'shape': [2048, 64], 'type': 'tensor'}, {'dtype': 'float', 'shape': [2048, 36], 'type': 'tensor'}]}, {'type': 'int', 'value': 1}]\n",
      "  input: [{'size': 2, 'type': 'genericlist', 'value': [{'dtype': 'float', 'shape': [2048, 1, 64], 'type': 'tensor'}, {'dtype': 'float', 'shape': [2048, 8, 64], 'type': 'tensor'}]}, {'type': 'int', 'value': 1}]\n",
      "op: aten::detach\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [], 'type': 'tensor'}]\n",
      "op: aten::detach_\n",
      "  count: 2\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'long int', 'shape': [36], 'type': 'tensor'}]\n",
      "op: aten::empty\n",
      "  count: 10\n",
      "  unique inputs:\n",
      "  input: [{'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 16}]}, {'type': 'int', 'value': 0}, {'type': 'none'}, {'type': 'device', 'value': 'cpu'}, {'type': 'none'}, {'type': 'none'}]\n",
      "  input: [{'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 36}]}, {'type': 'int', 'value': 4}, {'type': 'int', 'value': 0}, {'type': 'device', 'value': 'cpu'}, {'type': 'bool', 'value': False}, {'type': 'none'}]\n",
      "op: aten::index\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 9, 9], 'type': 'tensor'}, {'size': 3, 'type': 'genericlist', 'value': [{'dtype': 'nullptr (uninitialized)', 'shape': [], 'type': 'tensor'}, {'dtype': 'long int', 'shape': [36], 'type': 'tensor'}, {'dtype': 'long int', 'shape': [36], 'type': 'tensor'}]}]\n",
      "op: aten::linear\n",
      "  count: 6\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 1024], 'type': 'tensor'}, {'dtype': 'float', 'shape': [1, 1024], 'type': 'tensor'}, {'dtype': 'float', 'shape': [1], 'type': 'tensor'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 1024], 'type': 'tensor'}, {'dtype': 'float', 'shape': [1024, 1024], 'type': 'tensor'}, {'dtype': 'float', 'shape': [1024], 'type': 'tensor'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 512], 'type': 'tensor'}, {'dtype': 'float', 'shape': [512, 512], 'type': 'tensor'}, {'dtype': 'float', 'shape': [512], 'type': 'tensor'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 512], 'type': 'tensor'}, {'dtype': 'float', 'shape': [64, 512], 'type': 'tensor'}, {'dtype': 'float', 'shape': [64], 'type': 'tensor'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 100], 'type': 'tensor'}, {'dtype': 'float', 'shape': [1024, 100], 'type': 'tensor'}, {'dtype': 'float', 'shape': [1024], 'type': 'tensor'}]\n",
      "op: aten::mse_loss\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 1], 'type': 'tensor'}, {'dtype': 'float', 'shape': [2048, 1], 'type': 'tensor'}, {'type': 'int', 'value': 1}]\n",
      "op: aten::ones\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: [{'size': 2, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 2048}, {'type': 'int', 'value': 1}]}, {'type': 'int', 'value': 6}, {'type': 'none'}, {'type': 'device', 'value': 'cpu'}, {'type': 'bool', 'value': False}]\n",
      "op: aten::ones_like\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [], 'type': 'tensor'}, {'type': 'int', 'value': 6}, {'type': 'int', 'value': 0}, {'type': 'device', 'value': 'cuda:0'}, {'type': 'bool', 'value': False}, {'type': 'int', 'value': 1}]\n",
      "op: aten::relu\n",
      "  count: 5\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 1024], 'type': 'tensor'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 512], 'type': 'tensor'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 64], 'type': 'tensor'}]\n",
      "op: aten::sigmoid\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 1], 'type': 'tensor'}]\n",
      "op: aten::slice\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 9, 9], 'type': 'tensor'}, {'type': 'int', 'value': 0}, {'type': 'int', 'value': 0}, {'type': 'int', 'value': 9223372036854775807}, {'type': 'int', 'value': 1}]\n",
      "op: aten::sum\n",
      "  count: 6\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 512], 'type': 'tensor'}, {'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 0}]}, {'type': 'bool', 'value': True}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 64], 'type': 'tensor'}, {'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 0}]}, {'type': 'bool', 'value': True}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 1024], 'type': 'tensor'}, {'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 0}]}, {'type': 'bool', 'value': True}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 1], 'type': 'tensor'}, {'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 0}]}, {'type': 'bool', 'value': True}, {'type': 'none'}]\n",
      "op: aten::to\n",
      "  count: 11\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'int', 'shape': [16385], 'type': 'tensor'}, {'type': 'int', 'value': 3}, {'type': 'int', 'value': 0}, {'type': 'device', 'value': 'cuda:0'}, {'type': 'none'}, {'type': 'bool', 'value': False}, {'type': 'bool', 'value': False}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'float', 'shape': [], 'type': 'tensor'}, {'type': 'int', 'value': 6}, {'type': 'int', 'value': 0}, {'type': 'device', 'value': 'cpu'}, {'type': 'none'}, {'type': 'bool', 'value': False}, {'type': 'bool', 'value': False}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'int', 'shape': [1638400], 'type': 'tensor'}, {'type': 'int', 'value': 3}, {'type': 'int', 'value': 0}, {'type': 'device', 'value': 'cuda'}, {'type': 'none'}, {'type': 'bool', 'value': True}, {'type': 'bool', 'value': False}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 512], 'type': 'tensor'}, {'type': 'int', 'value': 6}, {'type': 'int', 'value': 0}, {'type': 'device', 'value': 'cuda:0'}, {'type': 'none'}, {'type': 'bool', 'value': False}, {'type': 'bool', 'value': False}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'int', 'shape': [16385], 'type': 'tensor'}, {'type': 'int', 'value': 3}, {'type': 'int', 'value': 0}, {'type': 'device', 'value': 'cuda'}, {'type': 'none'}, {'type': 'bool', 'value': True}, {'type': 'bool', 'value': False}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'int', 'shape': [1638400], 'type': 'tensor'}, {'type': 'int', 'value': 3}, {'type': 'int', 'value': 0}, {'type': 'device', 'value': 'cuda:0'}, {'type': 'none'}, {'type': 'bool', 'value': False}, {'type': 'bool', 'value': False}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'long int', 'shape': [36], 'type': 'tensor'}, {'type': 'device', 'value': 'cpu'}, {'type': 'int', 'value': 4}, {'type': 'bool', 'value': False}, {'type': 'bool', 'value': False}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'long int', 'shape': [36], 'type': 'tensor'}, {'type': 'int', 'value': 4}, {'type': 'int', 'value': 0}, {'type': 'device', 'value': 'cuda:0'}, {'type': 'none'}, {'type': 'bool', 'value': False}, {'type': 'bool', 'value': False}, {'type': 'none'}]\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 1], 'type': 'tensor'}, {'type': 'int', 'value': 6}, {'type': 'int', 'value': 0}, {'type': 'device', 'value': 'cuda:0'}, {'type': 'none'}, {'type': 'bool', 'value': False}, {'type': 'bool', 'value': False}, {'type': 'none'}]\n",
      "op: aten::transpose\n",
      "  count: 1\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 9, 64], 'type': 'tensor'}, {'type': 'int', 'value': 1}, {'type': 'int', 'value': 2}]\n",
      "op: aten::view\n",
      "  count: 7\n",
      "  unique inputs:\n",
      "  input: [{'dtype': 'float', 'shape': [2048, 64], 'type': 'tensor'}, {'size': 3, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 2048}, {'type': 'int', 'value': 1}, {'type': 'int', 'value': 64}]}]\n",
      "  input: [{'dtype': 'float', 'shape': [1, 1024], 'type': 'tensor'}, {'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 1024}]}]\n",
      "  input: [{'dtype': 'float', 'shape': [1, 64], 'type': 'tensor'}, {'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 64}]}]\n",
      "  input: [{'dtype': 'float', 'shape': [1, 512], 'type': 'tensor'}, {'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 512}]}]\n",
      "  input: [{'dtype': 'float', 'shape': [1, 1], 'type': 'tensor'}, {'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 1}]}]\n",
      "op: aten::zeros\n",
      "  count: 11\n",
      "  unique inputs:\n",
      "  input: [{'size': 1, 'type': 'genericlist', 'value': [{'type': 'int', 'value': 1}]}, {'type': 'int', 'value': 6}, {'type': 'none'}, {'type': 'device', 'value': 'cpu'}, {'type': 'bool', 'value': False}]\n",
      "op: torch::autograd::AccumulateGrad\n",
      "  count: 13\n",
      "  unique inputs:\n",
      "  input: []\n"
     ]
    }
   ],
   "source": [
    "graph.print_op_stats(detail=False, clean=True, json_format=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_size = 6 * 1024 * 1024 * 4\n",
    "num_SM = 80\n",
    "peak_dram_bw = 809 # GB/s\n",
    "peak_l2_bw = 2888 # GB/s\n",
    "peak_throughput = 12200 # GFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4340.7676440049445"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embedding_forward_predictor(peak_dram_bw, peak_l2_bw, L2_size, num_SM, **kwargs):\n",
    "    # hit_rate = C(X, L) / C(E, L), X = avg_num_rows_per_table\n",
    "    def hit_rate(X, E, L):\n",
    "        ret = 1.0\n",
    "        e = E\n",
    "        x = X\n",
    "        for idx in range(L):\n",
    "            ret *= x / e\n",
    "            x -= 1\n",
    "            e -= 1\n",
    "        return ret\n",
    "\n",
    "    # Average number of rows per table in L2\n",
    "    y = kwargs\n",
    "    num_total_warps = y[\"batch_size\"] * y[\"num_tables\"] # Total warp number of the kernel\n",
    "    num_warps_per_sm = y[\"rows_per_block\"] # Number of warps per sm\n",
    "    num_warps_simul = num_SM * num_warps_per_sm # Total number of warps simultaneously running on the device\n",
    "    num_tables_simul = (num_warps_simul + y[\"batch_size\"] - 1) // y[\"batch_size\"] # Number of tables simultaneously being accessed on the device\n",
    "    avg_table_size = min(L2_size // num_tables_simul, y[\"num_embeddings\"] * y[\"embedding_dim\"] * 4) # Average table size that reside on the device\n",
    "    indices_size = 0\n",
    "    avg_num_rows_per_table = (avg_table_size - indices_size) // 4 // y[\"embedding_dim\"]\n",
    "\n",
    "    # Hit rate\n",
    "    hr = hit_rate(avg_num_rows_per_table, y[\"num_embeddings\"], y[\"bag_size\"])\n",
    "    \n",
    "    # num_thread_x\n",
    "    num_thread_x = max(y[\"embedding_dim\"] / 4, 1024 / y[\"rows_per_block\"])\n",
    "\n",
    "    # Traffics\n",
    "    table_offsets_traffic = 32\n",
    "    offsets_traffic = 32\n",
    "    indices_dram_traffic = div_round_up(y[\"bag_size\"] * 4, 32) * 32\n",
    "    indices_l2_traffic = 0\n",
    "    table_traffic = y[\"bag_size\"] * (div_round_up(y[\"embedding_dim\"] * 4, 32) * 32)\n",
    "    output_traffic = (div_round_up(y[\"embedding_dim\"] * 4, 32) * 32)\n",
    "\n",
    "    # avg_table_size all as dram traffic\n",
    "    # 21, 26, 13, 7, 4, 4, 24, (0.2 Â± 0.21)\n",
    "    total_l2_traffic = ((table_offsets_traffic + offsets_traffic + indices_l2_traffic) * y[\"batch_size\"] + \\\n",
    "                        hr * (table_traffic * y[\"batch_size\"] - avg_table_size)) * y[\"num_tables\"]\n",
    "    total_dram_traffic = ((indices_dram_traffic + output_traffic) * y[\"batch_size\"] + \\\n",
    "                          (1 - hr) * (table_traffic * y[\"batch_size\"] - avg_table_size) + avg_table_size) * y[\"num_tables\"]\n",
    "\n",
    "    return max(total_dram_traffic / peak_dram_bw / 1000.0, total_l2_traffic / peak_l2_bw / 1000.0)\n",
    "        \n",
    "# e.g. 4340 vs 4789\n",
    "embedding_forward_predictor(peak_dram_bw, peak_l2_bw, L2_size, num_SM, batch_size=4096, num_embeddings=500000, num_tables=197, bag_size=32, embedding_dim=32, rows_per_block=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "elf_data = pd.read_csv('../data/embedding_lookup_1_shmem.csv', delimiter=',')\n",
    "elf_data = preprocessing(elf_data)\n",
    "elf_data = elf_data[elf_data[\"kernel_name\"].str.contains(\"batched_embedding\")]\n",
    "elf_data = elf_data[elf_data['batch_size'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% - 5%: 25.29%\n",
      "5% - 10%: 14.39%\n",
      "10% - 15%: 8.97%\n",
      "15% - 20%: 9.42%\n",
      "20% - 25%: 9.71%\n",
      "25% - 30%: 6.02%\n",
      "30% - 40%: 7.04%\n",
      "40% - 50%: 5.28%\n",
      "50% - 60%: 4.06%\n",
      "60% - 80%: 9.28%\n",
      "80% - 100%: 0.43%\n",
      "100% - 150%: 0.12%\n",
      "150% - 200%: 0.00%\n",
      "200% - 300%: 0.00%\n",
      "300% - 400%: 0.00%\n",
      "==== All sizes ====\n",
      "GMAE: 11.66%, mean: 21.98%, std: 21.00%\n",
      "0% - 5%: 27.79%\n",
      "5% - 10%: 21.77%\n",
      "10% - 15%: 10.75%\n",
      "15% - 20%: 10.89%\n",
      "20% - 25%: 16.29%\n",
      "25% - 30%: 5.75%\n",
      "30% - 40%: 5.61%\n",
      "40% - 50%: 1.15%\n",
      "50% - 60%: 0.00%\n",
      "60% - 80%: 0.00%\n",
      "80% - 100%: 0.00%\n",
      "100% - 150%: 0.00%\n",
      "150% - 200%: 0.00%\n",
      "200% - 300%: 0.00%\n",
      "300% - 400%: 0.00%\n",
      "==== Big sizes ====\n",
      "GMAE: 8.68%, mean: 13.13%, std: 9.99%\n"
     ]
    }
   ],
   "source": [
    "elf_time_all = elf_data.apply(lambda x: embedding_forward_predictor(peak_dram_bw, peak_l2_bw, L2_size, num_SM, **x[1:7]), axis=1)\n",
    "error_all = abs_err(elf_time_all, elf_data['kernel_runtime'])\n",
    "histogram(error_all)\n",
    "print(\"==== All sizes ====\")\n",
    "print(\"GMAE: {:.2f}%, mean: {:.2f}%, std: {:.2f}%\".format(gmae(error_all) * 100.0, error_all.mean() * 100.0, error_all.std() * 100.0))\n",
    "elf_time_big = elf_data[elf_data['num_embeddings'] >= 100000].apply(lambda x: embedding_forward_predictor(peak_dram_bw, peak_l2_bw, L2_size, num_SM, **x[1:7]), axis=1)\n",
    "error_big = abs_err(elf_time_big, elf_data[elf_data['num_embeddings'] >= 100000]['kernel_runtime'])\n",
    "histogram(error_big)\n",
    "print(\"==== Big sizes ====\")\n",
    "print(\"GMAE: {:.2f}%, mean: {:.2f}%, std: {:.2f}%\".format(gmae(error_big) * 100.0, error_big.mean() * 100.0, error_big.std() * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42834.783248454885"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embedding_backward_sgd_predictor(peak_dram_bw, **kwargs):\n",
    "    y = kwargs\n",
    "    indices_traffic = div_round_up(y[\"bag_size\"] * 4, 32) * 32\n",
    "    grad_output_traffic = div_round_up(y[\"embedding_dim\"] * 4, 32) * 32\n",
    "\n",
    "    # Traffic per warp = t_offsets + t_table_offsets + t_indices + t_weights + t_grad_outputs\n",
    "    total_traffic_per_warp = 32 + \\\n",
    "                            64 + \\\n",
    "                            indices_traffic + \\\n",
    "                            2 * y[\"bag_size\"] * (div_round_up(y[\"embedding_dim\"] * 4, 32) * 32) + \\\n",
    "                            grad_output_traffic\n",
    "\n",
    "    # Traffic = warp * traffic per warp\n",
    "    total_traffic = y[\"batch_size\"] * y[\"num_tables\"] * total_traffic_per_warp\n",
    "\n",
    "    # Total compute throughput\n",
    "    mac_per_warp = y[\"bag_size\"] * 4 * (y[\"embedding_dim\"] // 4)\n",
    "    total_mac = y[\"batch_size\"] * y[\"num_tables\"] * mac_per_warp\n",
    "\n",
    "    return max(total_traffic / peak_dram_bw / 1000, total_mac / peak_throughput / 1000)\n",
    "\n",
    "# e.g 42834 vs 44601\n",
    "embedding_backward_sgd_predictor(peak_dram_bw, batch_size=2048, num_embeddings=200000, num_tables=128, bag_size=128, embedding_dim=128, rows_per_block=32, shmem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [14885288    29419    15123     7291    19899        3     6463     1310\n",
    "#        61 10155909   618195   218994       10     2208     9779       71\n",
    "#         4      963       14 16967044  4154705 13180313   289595    10828\n",
    "#        95       34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_time(op, addmm_list, bmm_list, tril_list):\n",
    "    kernel_times = []\n",
    "    if op.name == \"aten::linear\":\n",
    "        for child in op.children:\n",
    "            if \"aten::t\" in child.name:\n",
    "                M, N = child.input_shapes[0][0], child.input_shapes[0][1]\n",
    "                t = inference(\"transpose\", \"1-{}-{}\".format(M, N))\n",
    "                kernel_times.append(t)\n",
    "#                 print(\"transpose\", 1, M, N, \"{:.2f}\".format(t))\n",
    "            else: # addmm\n",
    "                addmm_list.append(child)\n",
    "                M, K, N = child.input_shapes[1][0], child.input_shapes[1][1], child.input_shapes[2][1]\n",
    "                t = inference(\"fully_connected\", \"1-{}-{}-{}\".format(M, N, K))\n",
    "                kernel_times.append(t)\n",
    "#                 print(\"addmm\", M, N, K, \"{:.2f}\".format(t))\n",
    "    if op.name == \"AddmmBackward\":\n",
    "        addmm_op = addmm_list.pop()\n",
    "        M, K, N = addmm_op.input_shapes[1][0], addmm_op.input_shapes[1][1], addmm_op.input_shapes[2][1]\n",
    "        m1, k1, n1 = M, N, K\n",
    "        m2, k2, n2 = N, M, K\n",
    "        t1 = inference(\"fully_connected\", \"1-{}-{}-{}\".format(m1, n1, k1))\n",
    "        kernel_times.append(t1)\n",
    "        t2 = 0\n",
    "        if M != N:\n",
    "            t2 = inference(\"fully_connected\", \"1-{}-{}-{}\".format(m2, n2, k2))\n",
    "            kernel_times.append(t2)\n",
    "        t = t1 + t2\n",
    "#         print(\"addmm backward\", M, N, K, \"{:.2f}\".format(t1), \"{:.2f}\".format(t2), \"{:.2f}\".format(t))\n",
    "    if op.name == \"aten::bmm\":\n",
    "        bmm_list.append(op)\n",
    "        batch_size, M, K, N = op.input_shapes[0][0], op.input_shapes[0][1], op.input_shapes[0][2], op.input_shapes[1][2]\n",
    "        t = inference(\"fully_connected\", \"{}-{}-{}-{}\".format(batch_size, M, N, K))\n",
    "        kernel_times.append(t)\n",
    "#         print(\"bmm\", batch_size, M, N, K, \"{:.2f}\".format(t))\n",
    "    if op.name == \"BmmBackward0\":\n",
    "        bmm_op = bmm_list.pop()\n",
    "        batch_size, M, K, N = bmm_op.input_shapes[0][0], bmm_op.input_shapes[0][1], bmm_op.input_shapes[0][2], bmm_op.input_shapes[1][2]\n",
    "        m1, k1, n1 = N, M, K\n",
    "        m2, k2, n2 = M, N, K\n",
    "        t1 = inference(\"fully_connected\", \"{}-{}-{}-{}\".format(batch_size, m1, n1, k1))\n",
    "        t2 = inference(\"fully_connected\", \"{}-{}-{}-{}\".format(batch_size, m2, n2, k2))\n",
    "        kernel_times.append(t1)\n",
    "        kernel_times.append(t2)\n",
    "        t = t1 + t2\n",
    "#         print(\"bmm backward\", batch_size, M, N, K, \"{:.2f}\".format(t1), \"{:.2f}\".format(t2), \"{:.2f}\".format(t))\n",
    "    if op.name == \"LookupFunction\":\n",
    "        if model_name == \"MLPerf_1\":\n",
    "            Es = [14885288, 29419, 15123, 7291, 19899, 3, 6463, 1310, 61, 10155909, 618195, 218994, 10, 2208, 9779, 71, 4, 963, 14, 16967044, 4154705, 13180313, 289595, 10828, 95, 34] \n",
    "            B, E, T, L, D, rows_per_block = 2048, int(np.mean(Es)), len(Es), 1, 128, 2\n",
    "        else:\n",
    "            B, E, T, L, D, rows_per_block = 2048, 1000000, 8, 100, 64, 4\n",
    "        t = embedding_forward_predictor(peak_dram_bw, peak_l2_bw, L2_size, num_SM, batch_size=B, num_embeddings=E, num_tables=T, bag_size=L, embedding_dim=D, rows_per_block=rows_per_block)\n",
    "        kernel_times.append(t)\n",
    "#         print(\"Embedding forward\", t)\n",
    "    if op.name == \"LookupFunctionBackward\":\n",
    "        if model_name == \"MLPerf_1\":\n",
    "            Es = [14885288, 29419, 15123, 7291, 19899, 3, 6463, 1310, 61, 10155909, 618195, 218994, 10, 2208, 9779, 71, 4, 963, 14, 16967044, 4154705, 13180313, 289595, 10828, 95, 34] \n",
    "            B, E, T, L, D, rows_per_block = 2048, int(np.mean(Es)), len(Es), 1, 128, 2\n",
    "        else:\n",
    "            B, E, T, L, D, rows_per_block = 2048, 1000000, 8, 100, 64, 4\n",
    "        t = embedding_backward_sgd_predictor(peak_dram_bw, batch_size=B, num_embeddings=E, num_tables=T, bag_size=L, embedding_dim=D, rows_per_block=rows_per_block)\n",
    "        kernel_times.append(t)\n",
    "#         print(\"Embedding backward\", t)\n",
    "    if op.name == \"aten::t\":\n",
    "        kernel_times.append(0) # T is handled under addmm\n",
    "    if op.name == \"aten::relu\":\n",
    "#             print(op.input_shapes)\n",
    "        pass\n",
    "    if op.name == \"aten::sigmoid\":\n",
    "#             print(op.input_shapes)\n",
    "        pass\n",
    "    if op.name == \"aten::add\":\n",
    "#             print(op.input_shapes)\n",
    "        pass\n",
    "    if op.name == \"aten::index\":\n",
    "        tril_list.append(op)\n",
    "        batch_size, M, N = op.input_shapes[0][0], op.input_shapes[0][1], op.input_shapes[0][2]\n",
    "        total_output_element = op.input_shapes[1][1][0]\n",
    "        if total_output_element == int(M * (1+N) / 2):\n",
    "            diag = 1\n",
    "        else:\n",
    "            diag = 0\n",
    "        t = inference(\"tril\", \"{}-{}-{}-{}\".format(batch_size, M, N, diag), backward=False)\n",
    "        kernel_times.append(t)\n",
    "#         print(\"tril\", batch_size, M, N, diag, \"{:.2f}\".format(t))\n",
    "    if op.name == \"IndexBackward\": # See all kernels as a whole\n",
    "        tril_op = tril_list.pop()\n",
    "        batch_size, M, N = tril_op.input_shapes[0][0], tril_op.input_shapes[0][1], tril_op.input_shapes[0][2]\n",
    "        total_output_element = tril_op.input_shapes[1][1][0]\n",
    "        if total_output_element == int(M * (1+N) / 2):\n",
    "            diag = 1\n",
    "        else:\n",
    "            diag = 0\n",
    "        t = inference(\"tril\", \"{}-{}-{}-{}\".format(batch_size, M, N, diag), backward=True)\n",
    "        kernel_times.append(t)\n",
    "#         print(\"tril backward\", batch_size, M, N, diag, \"{:.2f}\".format(t))\n",
    "    return kernel_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'launches': {'AddmmBackward': ['cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel'],\n",
      "              'BmmBackward0': ['cudaLaunchKernel', 'cudaLaunchKernel'],\n",
      "              'IndexBackward': ['cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel',\n",
      "                                'cudaLaunchKernel'],\n",
      "              'LookupFunction': ['cudaLaunchKernel'],\n",
      "              'LookupFunctionBackward': ['cudaLaunchKernel'],\n",
      "              'MseLossBackward': ['cudaLaunchKernel', 'cudaLaunchKernel'],\n",
      "              'Optimizer.step#SGD.step': ['cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel',\n",
      "                                          'cudaLaunchKernel'],\n",
      "              'Optimizer.zero_grad#SGD.zero_grad': ['cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel',\n",
      "                                                    'cudaLaunchKernel'],\n",
      "              'ReluBackward0': ['cudaLaunchKernel'],\n",
      "              'SigmoidBackward': ['cudaLaunchKernel'],\n",
      "              'SliceBackward': ['cudaLaunchKernel', 'cudaMemcpyAsync'],\n",
      "              'aten::add': ['cudaLaunchKernel'],\n",
      "              'aten::bmm': ['cudaLaunchKernel'],\n",
      "              'aten::cat': ['cudaLaunchKernel'],\n",
      "              'aten::index': ['cudaLaunchKernel'],\n",
      "              'aten::linear': ['cudaLaunchKernel', 'cudaLaunchKernel'],\n",
      "              'aten::mse_loss': ['cudaLaunchKernel', 'cudaLaunchKernel'],\n",
      "              'aten::ones_like': ['cudaLaunchKernel'],\n",
      "              'aten::relu': ['cudaLaunchKernel'],\n",
      "              'aten::sigmoid': ['cudaLaunchKernel'],\n",
      "              'aten::sum': ['cudaLaunchKernel'],\n",
      "              'aten::to': ['cudaMemcpyAsync'],\n",
      "              'torch::autograd::AccumulateGrad': ['cudaLaunchKernel']},\n",
      " 't1': [14.592929292929293, 13.466417283358851],\n",
      " 't2': {'AddmmBackward': [68.63333333333334, 7.947676110383183],\n",
      "        'BmmBackward0': [72.5, 2.1095023109728985],\n",
      "        'IndexBackward': [35.6, 2.33238075793812],\n",
      "        'LookupFunction': [73.7, 2.0024984394500787],\n",
      "        'LookupFunctionBackward': [46.2, 0.8717797887081347],\n",
      "        'MseLossBackward': [54.3, 3.3778691508109073],\n",
      "        'Optimizer.step#SGD.step': [141.2, 4.955804677345546],\n",
      "        'Optimizer.zero_grad#SGD.zero_grad': [96.6, 1.9595917942265424],\n",
      "        'ReluBackward0': [24.82, 1.8835073665903195],\n",
      "        'SigmoidBackward': [26.7, 1.1874342087037917],\n",
      "        'SliceBackward': [28.7, 0.9],\n",
      "        'aten::add': [14.95, 1.8834808201837363],\n",
      "        'aten::bmm': [50.5, 2.8372521918222215],\n",
      "        'aten::cat': [42.5, 4.695742752749559],\n",
      "        'aten::index': [65.1, 3.7802116342871597],\n",
      "        'aten::linear': [71.8, 10.335698654017863],\n",
      "        'aten::mse_loss': [31.3, 0.9],\n",
      "        'aten::ones_like': [36.8, 5.436910887627275],\n",
      "        'aten::relu': [43.46, 3.4188302092967415],\n",
      "        'aten::sigmoid': [19.2, 0.6],\n",
      "        'aten::sum': [37.21666666666667, 4.647908729262609],\n",
      "        'aten::to': [27.571428571428573, 6.14485017502212],\n",
      "        'torch::autograd::AccumulateGrad': [12.241666666666667,\n",
      "                                            2.4832634218347076]},\n",
      " 't3': {'AddmmBackward': [30.366666666666667, 2.2506789099193063],\n",
      "        'BmmBackward0': [8.1, 1.374772708486752],\n",
      "        'IndexBackward': [13.0, 1.7888543819998317],\n",
      "        'LookupFunction': [27.9, 0.8306623862918073],\n",
      "        'LookupFunctionBackward': [72.1, 2.6248809496813377],\n",
      "        'MseLossBackward': [12.0, 0.6324555320336759],\n",
      "        'Optimizer.step#SGD.step': [34.0, 0.8944271909999159],\n",
      "        'Optimizer.zero_grad#SGD.zero_grad': [17.2, 1.0770329614269007],\n",
      "        'ReluBackward0': [8.28, 1.497197381777032],\n",
      "        'SigmoidBackward': [7.0, 0.4472135954999579],\n",
      "        'SliceBackward': [10.2, 1.4],\n",
      "        'aten::add': [4.65, 0.5722761571129799],\n",
      "        'aten::bmm': [8.7, 0.6403124237432849],\n",
      "        'aten::cat': [8.95, 1.4309088021254184],\n",
      "        'aten::index': [8.2, 0.4],\n",
      "        'aten::linear': [14.616666666666667, 2.726974310272997],\n",
      "        'aten::mse_loss': [14.0, 1.7888543819998317],\n",
      "        'aten::ones_like': [5.8, 0.39999999999999997],\n",
      "        'aten::relu': [11.66, 2.396747796494241],\n",
      "        'aten::sigmoid': [8.1, 0.5385164807134504],\n",
      "        'aten::sum': [7.15, 2.322534535085898],\n",
      "        'aten::to': [197.45714285714286, 192.54889440008188],\n",
      "        'torch::autograd::AccumulateGrad': [7.583333333333333,\n",
      "                                            1.9899050786965249]},\n",
      " 't4': {'cudaLaunchKernel': [10.8933582787652, 3.6232596020508043],\n",
      "        'cudaMemcpyAsync': [17.1375, 6.71703757247196]},\n",
      " 't5': {'AddmmBackward': [46.22222222222222, 40.913670026798236],\n",
      "        'BmmBackward0': [58.2, 2.2271057451320084],\n",
      "        'CatBackward': [33.0, 0.0],\n",
      "        'IndexBackward': [34.42424242424242, 18.219808794465628],\n",
      "        'LookupFunction': [0.0, 0.0],\n",
      "        'LookupFunctionBackward': [0.0, 0.0],\n",
      "        'MseLossBackward': [26.7, 2.8653097563788807],\n",
      "        'Optimizer.step#SGD.step': [16.654545454545456, 2.064577278486561],\n",
      "        'Optimizer.zero_grad#SGD.zero_grad': [23.954545454545453,\n",
      "                                              2.738235542150733],\n",
      "        'ReluBackward0': [0.0, 0.0],\n",
      "        'SigmoidBackward': [0.0, 0.0],\n",
      "        'SliceBackward': [34.0, 5.385164807134504],\n",
      "        'TBackward': [17.0, 0.0],\n",
      "        'TransposeBackward0': [13.0, 0.0],\n",
      "        'ViewBackward': [13.0, 0.0],\n",
      "        'aten::add': [0.0, 0.0],\n",
      "        'aten::bmm': [0.0, 0.0],\n",
      "        'aten::broadcast_tensors': [4.0, 0.0],\n",
      "        'aten::cat': [0.0, 0.0],\n",
      "        'aten::detach': [10.0, 0.0],\n",
      "        'aten::detach_': [5.0, 0.0],\n",
      "        'aten::empty': [3.0, 0.0],\n",
      "        'aten::index': [0.0, 0.0],\n",
      "        'aten::linear': [37.733333333333334, 9.758529033050468],\n",
      "        'aten::mse_loss': [42.6, 1.8],\n",
      "        'aten::ones': [22.0, 0.0],\n",
      "        'aten::ones_like': [0.0, 0.0],\n",
      "        'aten::relu': [0.0, 0.0],\n",
      "        'aten::sigmoid': [0.0, 0.0],\n",
      "        'aten::slice': [15.0, 0.0],\n",
      "        'aten::sum': [0.0, 0.0],\n",
      "        'aten::to': [0.2, 0.4000000000000001],\n",
      "        'aten::transpose': [13.0, 0.0],\n",
      "        'aten::view': [5.0, 0.0],\n",
      "        'aten::zeros': [17.0, 0.0],\n",
      "        'torch::autograd::AccumulateGrad': [8.0, 16.0]}}\n"
     ]
    }
   ],
   "source": [
    "pprint(overheads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::empty 17.59292929292929\n",
      "aten::ones 54.18585858585858\n",
      "aten::zeros 85.77878787878788\n",
      "aten::empty 103.37171717171718\n",
      "aten::to 360.13071789321793\n",
      "aten::to 616.8897186147186\n",
      "aten::to 873.6487193362193\n",
      "aten::zeros 905.2416486291486\n",
      "aten::empty 922.8345779220779\n",
      "aten::linear 1083.3642237725373\n",
      "aten::relu 1163.970511344232\n",
      "aten::linear 1324.5001571946914\n",
      "aten::relu 1405.106444766386\n",
      "aten::zeros 1436.6993740593152\n",
      "aten::empty 1454.2923033522445\n",
      "aten::to 1711.0513040737453\n",
      "aten::to 1967.810304795246\n",
      "LookupFunction 2094.8965923669407\n",
      "aten::zeros 2126.48952165987\n",
      "aten::empty 2144.0824509527997\n",
      "aten::view 2163.6753802457292\n",
      "aten::cat 2240.611667817424\n",
      "aten::transpose 2268.2045971103535\n",
      "aten::bmm 2352.890884682048\n",
      "aten::empty 2370.4838139749777\n",
      "aten::to 2627.2428146964785\n",
      "aten::detach_ 2646.835743989408\n",
      "aten::empty 2664.4286732823375\n",
      "aten::to 2921.1876740038383\n",
      "aten::detach_ 2940.780603296768\n",
      "aten::slice 2970.3735325896973\n",
      "aten::to 3227.132533311198\n",
      "aten::to 3483.891534032699\n",
      "aten::index 3582.6778216043936\n",
      "aten::cat 3659.6141091760883\n",
      "aten::zeros 3691.207038469018\n",
      "aten::empty 3708.7999677619473\n",
      "aten::linear 3869.3296136124077\n",
      "aten::relu 3949.9359011841025\n",
      "aten::linear 4110.465547034562\n",
      "aten::relu 4191.071834606257\n",
      "aten::linear 4351.601480456717\n",
      "aten::relu 4432.207768028411\n",
      "aten::linear 4592.737413878871\n",
      "aten::sigmoid 4645.523701450566\n",
      "aten::zeros 4677.116630743495\n",
      "aten::empty 4694.709560036425\n",
      "aten::to 4951.468560757925\n",
      "aten::broadcast_tensors 4970.061490050854\n",
      "aten::mse_loss 5094.341135901315\n",
      "aten::detach 5118.934065194245\n",
      "aten::to 5375.693065915745\n",
      "aten::zeros 5407.285995208675\n",
      "aten::empty 5424.878924501604\n",
      "aten::zeros 5456.471853794534\n",
      "Optimizer.zero_grad#SGD.zero_grad 5962.164783087464\n",
      "aten::ones_like 6030.251070659158\n",
      "MseLossBackward 6159.630716509619\n",
      "SigmoidBackward 6218.817004081313\n",
      "AddmmBackward 6457.5344526549825\n",
      "aten::sum 6527.387406893343\n",
      "aten::view 6546.980336186272\n",
      "torch::autograd::AccumulateGrad 6592.291623757967\n",
      "TBackward 6623.884553050896\n",
      "torch::autograd::AccumulateGrad 6669.19584062259\n",
      "ReluBackward0 6727.782128194284\n",
      "AddmmBackward 6966.499576767954\n",
      "aten::sum 7036.352531006314\n",
      "aten::view 7055.945460299244\n",
      "torch::autograd::AccumulateGrad 7101.256747870938\n",
      "TBackward 7132.849677163867\n",
      "torch::autograd::AccumulateGrad 7178.160964735562\n",
      "ReluBackward0 7236.747252307256\n",
      "AddmmBackward 7475.464700880925\n",
      "aten::sum 7545.3176551192855\n",
      "aten::view 7564.910584412215\n",
      "torch::autograd::AccumulateGrad 7610.221871983909\n",
      "TBackward 7641.814801276839\n",
      "torch::autograd::AccumulateGrad 7687.126088848533\n",
      "ReluBackward0 7745.712376420227\n",
      "AddmmBackward 7984.429824993897\n",
      "aten::sum 8054.282779232257\n",
      "aten::view 8073.875708525186\n",
      "torch::autograd::AccumulateGrad 8119.186996096881\n",
      "TBackward 8150.77992538981\n",
      "torch::autograd::AccumulateGrad 8196.091212961504\n",
      "CatBackward 8243.684142254433\n",
      "IndexBackward 8770.946436856197\n",
      "SliceBackward 8886.470224427892\n",
      "BmmBackward0 9061.649870278352\n",
      "TransposeBackward0 9089.24279957128\n",
      "aten::add 9134.329087142974\n",
      "CatBackward 9181.922016435903\n",
      "ViewBackward 9209.514945728832\n",
      "aten::add 9254.601233300526\n",
      "LookupFunctionBackward 9398.38752087222\n",
      "torch::autograd::AccumulateGrad 9443.698808443914\n",
      "ReluBackward0 9502.285096015608\n",
      "AddmmBackward 9741.002544589277\n",
      "aten::sum 9810.855498827637\n",
      "aten::view 9830.448428120566\n",
      "torch::autograd::AccumulateGrad 9875.75971569226\n",
      "TBackward 9907.352644985189\n",
      "torch::autograd::AccumulateGrad 9952.663932556883\n",
      "ReluBackward0 10011.250220128577\n",
      "AddmmBackward 10249.967668702246\n",
      "aten::sum 10319.820622940606\n",
      "aten::view 10339.413552233535\n",
      "torch::autograd::AccumulateGrad 10384.724839805229\n",
      "TBackward 10416.317769098157\n",
      "torch::autograd::AccumulateGrad 10461.629056669852\n",
      "aten::zeros 10493.22198596278\n",
      "Optimizer.step#SGD.step 11041.41491525571\n",
      "aten::zeros 11073.007844548638\n",
      "aten::zeros 11104.600773841566\n",
      "Total time is: 11104.600773841566\n",
      "GPU time is: 4912.719961772489\n"
     ]
    }
   ],
   "source": [
    "nodes = graph.get_nodes(clean=True) # dict\n",
    "sorted_nodes = sorted(nodes.items(), key=lambda x: x[0])\n",
    "addmm_list = []\n",
    "bmm_list = []\n",
    "tril_list = []\n",
    "cpu_time = 0\n",
    "gpu_time = 0\n",
    "gpu_active_time = 0\n",
    "\n",
    "consider = [\"aten::linear\", \"AddmmBackward\", \"aten::bmm\", \"BmmBackward0\", \"LookupFunction\", \"LookupFunctionBackward\", \"IndexBackward\", \"aten::index\"]\n",
    "whole = [\"Optimizer.zero_grad#SGD.zero_grad\", \"Optimizer.step#SGD.step\"]\n",
    "skip = [\"aten::random_\", \"aten::item\"]\n",
    "\n",
    "for id, op in sorted_nodes:\n",
    "    if op.name in skip:\n",
    "        continue\n",
    "    is_op = (op.type == NodeType.OPERATOR and op.parent.type != NodeType.OPERATOR)\n",
    "    if is_op:\n",
    "        cpu_time += overheads[\"t1\"][0] # T1: between two ops\n",
    "        if op.name in overheads[\"launches\"].keys(): # Has kernel calls\n",
    "            cpu_time += overheads[\"t2\"][op.name][0] # T2: before the first kernel call\n",
    "            launches = overheads[\"launches\"][op.name]\n",
    "            if op.name in consider:\n",
    "                t = get_kernel_time(op, addmm_list, bmm_list, tril_list) # Get kernel time\n",
    "\n",
    "                for idx, l in enumerate(launches):\n",
    "                    t4 = overheads[\"t4\"][l][0] # Kernel launches\n",
    "                    t5 = overheads[\"t5\"][op.name][0] # Avg overhead between\n",
    "#                     if \"AddmmBackward\" == op.name:\n",
    "#                         print(overheads[\"t2\"][op.name][0])\n",
    "#                         print(\"============\")\n",
    "#                         print(cpu_time)\n",
    "#                         print(t4)\n",
    "#                         print(t5)\n",
    "\n",
    "                    # Contribution of CPU overheads on GPU idle time\n",
    "                    gpu_time = max(gpu_time + 1, cpu_time + t4/2) # Where the kernel starts: either launch right after last kernel, or at the middle of the kernel launch\n",
    "                    \n",
    "                    if idx < len(t):\n",
    "                        gpu_time += t[idx]\n",
    "                    cpu_time += t4\n",
    "                    if idx < len(launches) - 1:\n",
    "                        cpu_time += t5\n",
    "                    \n",
    "#                     if \"AddmmBackward\" == op.name:\n",
    "#                         print(cpu_time)\n",
    "\n",
    "                gpu_active_time += np.sum(t)\n",
    "            else:\n",
    "                if op.name in whole:\n",
    "                    # Take the op as a whole without considering all its kernel calls\n",
    "                    cpu_time += overheads[\"t2\"][op.name][0] + overheads[\"t3\"][op.name][0] + overheads[\"t5\"][op.name][0] * (len(launches) - 1)\n",
    "                else:\n",
    "                    # Only consider CPU time then: op_cpu_time = T2 + (T4 sum) + (T5 sum) + T3\n",
    "                    cpu_time += overheads[\"t5\"][op.name][0] * (len(launches) - 1) # T5\n",
    "                    cpu_time += np.sum([overheads[\"t4\"][x][0] for x in launches]) # T4\n",
    "            cpu_time += overheads[\"t3\"][op.name][0] # T3: after the first kernel call\n",
    "        else:\n",
    "            cpu_time += overheads[\"t5\"][op.name][0] # Ops that have no kernel calls only have T5 overheads (total CPU overheads)\n",
    "        print(op.name, cpu_time)\n",
    "            \n",
    "total_time = max(gpu_time, cpu_time)\n",
    "        \n",
    "print(\"Total time is: {}\".format(total_time))\n",
    "print(\"GPU time is: {}\".format(gpu_active_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "disseminate_notebook_id": {
   "notebook_id": "573647873313879"
  },
  "disseminate_notebook_info": {
   "bento_version": "20200830-210251",
   "description": "Analyze a two-iteration trace file generated by ATC ; extract multi-level (module/op) runtime breakdown and major input output shapes.",
   "hide_code": false,
   "hipster_group": "",
   "kernel_build_info": {
    "error": "The file located at '/data/users/zhongyilin/fbsource/fbcode/bento/kernels/local/zhongyilin/TARGETS' could not be found."
   },
   "no_uii": true,
   "notebook_number": "320128",
   "others_can_edit": false,
   "reviewers": "",
   "revision_id": "643445799644945",
   "tags": "FBLSim,CEA,ATC,dyno,gputrace,trace",
   "tasks": "",
   "title": "Runtime Prediction"
  },
  "kernelspec": {
   "display_name": "zhongyi",
   "language": "python",
   "name": "zhongyi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
